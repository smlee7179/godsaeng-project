"""
AI ì„œë¹„ìŠ¤ - ì—¬ëŸ¬ AI API ì§€ì› (OpenAI, Hugging Face, Gemini, Ollama)
"""
from typing import List, Optional
from datetime import date
import json
import os
from app.config.settings import get_settings
from app.models.log import DailyLog

settings = get_settings()

class AIService:
    """AI ë¶„ì„ ì„œë¹„ìŠ¤ - ì—¬ëŸ¬ AI ì œê³µì ì§€ì›"""
    
    def __init__(self):
        self.provider = os.getenv("AI_PROVIDER", "huggingface").lower()
        self.api_key = None
        self.client = None
        
        # ì„¤ì •ëœ API í‚¤ í™•ì¸
        if self.provider == "openai":
            self.api_key = os.getenv("OPENAI_API_KEY") or settings.openai_api_key
            if self.api_key:
                try:
                    from openai import OpenAI
                    self.client = OpenAI(api_key=self.api_key)
                    print("âœ… OpenAI API ì‚¬ìš©")
                except ImportError:
                    print("âš ï¸ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif self.provider == "huggingface":
            self.api_key = os.getenv("HUGGINGFACE_API_KEY") or settings.huggingface_api_key
            if self.api_key:
                print("âœ… Hugging Face API í‚¤ ì‚¬ìš©")
            else:
                print("ğŸ’¡ Hugging Face API í‚¤ ì—†ìŒ - ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© (ì œí•œì )")
        elif self.provider == "gemini":
            self.api_key = os.getenv("GEMINI_API_KEY") or settings.gemini_api_key
            if self.api_key:
                try:
                    import google.generativeai as genai
                    genai.configure(api_key=self.api_key)
                    self.client = genai
                    print("âœ… Google Gemini API ì‚¬ìš©")
                except ImportError:
                    print("âš ï¸ Google Generative AI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif self.provider == "ollama":
            self.ollama_url = os.getenv("OLLAMA_URL") or settings.ollama_url
            print(f"âœ… Ollama ì‚¬ìš©: {self.ollama_url}")
        else:
            # ê¸°ë³¸ê°’ì„ huggingfaceë¡œ
            self.provider = "huggingface"
            self.api_key = os.getenv("HUGGINGFACE_API_KEY") or settings.huggingface_api_key
            if not self.api_key:
                print("ğŸ’¡ Hugging Face API í‚¤ ì—†ìŒ - ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© (ì œí•œì )")
    
    async def analyze_daily_logs(self, logs: List[DailyLog], target_date: date) -> dict:
        """
        ì¼ì¼ ê¸°ë¡ë“¤ì„ ë¶„ì„í•˜ì—¬ ìš”ì•½ ë° í”¼ë“œë°± ìƒì„±
        
        Args:
            logs: ë¶„ì„í•  ì¼ì¼ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
            target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            AI ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ê¸°ë¡ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        log_texts = []
        for log in logs:
            log_entry = f"- {log.activity}"
            if log.mood:
                log_entry += f" (ê°ì •: {log.mood})"
            if log.tags:
                log_entry += f" [íƒœê·¸: {', '.join(log.tags)}]"
            log_texts.append(log_entry)
        
        logs_summary = "\n".join(log_texts) if log_texts else "ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ê³µí†µ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ìƒì„ ë¶„ì„í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‚ ì§œ: {target_date}
ì˜¤ëŠ˜ì˜ í™œë™ ê¸°ë¡:
{logs_summary}

ìœ„ í™œë™ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. í•˜ë£¨ ìš”ì•½ (2-3ë¬¸ì¥)
2. ê°ì • ë¶„ì„ (ê°ì • í‚¤ì›Œë“œ 3-5ê°œ)
3. ì¸ì‚¬ì´íŠ¸ (íŒ¨í„´ì´ë‚˜ íŠ¹ì§• 2-3ê°œ)
4. ê°œì„  ì œì•ˆ (ì¶”ì²œì‚¬í•­ 2-3ê°œ)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "summary": "í•˜ë£¨ ìš”ì•½",
    "emotions": ["ê°ì •1", "ê°ì •2"],
    "insights": ["ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2"],
    "recommendations": ["ì¶”ì²œ1", "ì¶”ì²œ2"],
    "feedback": "ì „ì²´ì ì¸ í”¼ë“œë°± ë©”ì‹œì§€"
}}"""

        # ì œê³µìë³„ ì²˜ë¦¬
        if self.provider == "openai":
            return await self._analyze_with_openai(prompt)
        elif self.provider == "huggingface":
            return await self._analyze_with_huggingface(prompt)
        elif self.provider == "gemini":
            return await self._analyze_with_gemini(prompt)
        elif self.provider == "ollama":
            return await self._analyze_with_ollama(prompt)
        else:
            return await self._analyze_with_huggingface(prompt)  # ê¸°ë³¸ê°’
    
    async def _analyze_with_openai(self, prompt: str) -> dict:
        """OpenAI API ì‚¬ìš©"""
        if not self.client:
            return self._default_error_response("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ìƒì„ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            content = response.choices[0].message.content
            return self._parse_ai_response(content)
        except Exception as e:
            return self._default_error_response(f"OpenAI ì˜¤ë¥˜: {str(e)}")
    
    async def _analyze_with_huggingface(self, prompt: str) -> dict:
        """Hugging Face Inference API ì‚¬ìš© (ë¬´ë£Œ)"""
        try:
            import aiohttp
            
            # ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© (API í‚¤ ë¶ˆí•„ìš”)
            model = "meta-llama/Meta-Llama-3.2-3B-Instruct"  # ë¬´ë£Œ ëª¨ë¸
            api_url = f"https://api-inference.huggingface.co/models/{model}"
            
            headers = {
                "Content-Type": "application/json",
            }
            
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            
            payload = {
                "inputs": f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ìƒì„ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

{prompt}""",
                "parameters": {
                    "max_new_tokens": 1000,
                    "temperature": 0.7,
                    "return_full_text": False
                }
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=payload, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        content = result[0].get("generated_text", "")
                        return self._parse_ai_response(content)
                    elif response.status == 503:
                        # ëª¨ë¸ ë¡œë”© ì¤‘ì´ë©´ ë” ê°„ë‹¨í•œ ëª¨ë¸ ì‚¬ìš©
                        return await self._analyze_with_simple_model(prompt)
                    else:
                        return self._default_error_response(f"Hugging Face API ì˜¤ë¥˜: {response.status}")
        except ImportError:
            return await self._analyze_with_simple_model(prompt)
        except Exception as e:
            return await self._analyze_with_simple_model(prompt)
    
    async def _analyze_with_gemini(self, prompt: str) -> dict:
        """Google Gemini API ì‚¬ìš© (ë¬´ë£Œ í‹°ì–´)"""
        if not self.api_key:
            return self._default_error_response("Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        try:
            import google.generativeai as genai
            
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content(
                f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ìƒì„ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

{prompt}"""
            )
            content = response.text
            return self._parse_ai_response(content)
        except ImportError:
            return self._default_error_response("Google Generative AI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        except Exception as e:
            return self._default_error_response(f"Gemini ì˜¤ë¥˜: {str(e)}")
    
    async def _analyze_with_ollama(self, prompt: str) -> dict:
        """Ollama ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© (ì™„ì „ ë¬´ë£Œ)"""
        try:
            import aiohttp
            
            api_url = f"{self.ollama_url}/api/generate"
            payload = {
                "model": "llama3",  # ë˜ëŠ” llama2, mistral ë“±
                "prompt": f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ìƒì„ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

{prompt}""",
                "stream": False
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        content = result.get("response", "")
                        return self._parse_ai_response(content)
                    else:
                        return self._default_error_response("Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        except ImportError:
            return self._default_error_response("aiohttp íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        except Exception as e:
            return self._default_error_response(f"Ollama ì˜¤ë¥˜: {str(e)}")
    
    async def _analyze_with_simple_model(self, prompt: str) -> dict:
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (API ì—†ì´ ì‘ë™)"""
        # ê¸°ë³¸ì ì¸ ë¶„ì„ ì œê³µ
        return {
            "summary": "ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ê¸°ë¡í•˜ì‹  ëª¨ë“  í™œë™ì´ ì†Œì¤‘í•©ë‹ˆë‹¤. ì§€ì†ì ì¸ ê¸°ë¡ì„ í†µí•´ ë” ë‚˜ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "feedback": "ê·œì¹™ ê¸°ë°˜ ë¶„ì„ì…ë‹ˆë‹¤. ë” ì •í™•í•œ AI ë¶„ì„ì„ ìœ„í•´ Hugging Face API í‚¤ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ Ollamaë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
            "emotions": ["ê¸°ë¡", "ì„±ì¥", "ìê¸°ë°˜ì„±"],
            "insights": ["ì§€ì†ì ì¸ ê¸°ë¡ì˜ ê°€ì¹˜", "íŒ¨í„´ ê´€ì°°ì˜ ì¤‘ìš”ì„±"],
            "recommendations": ["ë” ë§ì€ ê¸°ë¡ì„ ë‚¨ê²¨ë³´ì„¸ìš”", "ì •ê¸°ì ìœ¼ë¡œ ìì‹ ì˜ íŒ¨í„´ì„ í™•ì¸í•´ë³´ì„¸ìš”"]
        }
    
    def _parse_ai_response(self, content: str) -> dict:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ ë°˜í™˜"""
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            result = json.loads(content)
            return {
                "summary": result.get("summary", "ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."),
                "feedback": result.get("feedback", ""),
                "emotions": result.get("emotions", []),
                "insights": result.get("insights", []),
                "recommendations": result.get("recommendations", [])
            }
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
            summary = content[:300] + "..." if len(content) > 300 else content
            return {
                "summary": summary,
                "feedback": "AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "emotions": [],
                "insights": [],
                "recommendations": []
            }
    
    def _default_error_response(self, error_msg: str) -> dict:
        """ê¸°ë³¸ ì˜¤ë¥˜ ì‘ë‹µ"""
        return {
            "summary": error_msg,
            "feedback": "ë¬´ë£Œ AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.",
            "emotions": [],
            "insights": [],
            "recommendations": []
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
ai_service = AIService()

